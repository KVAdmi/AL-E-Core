# üî¨ AN√ÅLISIS QUIR√öRGICO - SISTEMA DE VOZ
**Fecha**: 23 de enero de 2026, 17:30 hrs  
**Analista**: GitHub Copilot  
**Solicitado por**: Directora de Proyecto  
**Prop√≥sito**: Rastreo completo de 2 sistemas de voz (Chat + Reuniones) para encontrar cables rotos

---

## üéØ **SISTEMAS DE VOZ IDENTIFICADOS**

| Sistema | Ubicaci√≥n | Estado | Problema reportado |
|---------|-----------|--------|-------------------|
| **1. VOZ CHAT** | Sidebar ‚Üí VoiceButton | ‚ö†Ô∏è PARCIAL | Crea nueva sesi√≥n, no mantiene contexto |
| **2. VOZ REUNIONES** | Meetings ‚Üí MeetingsRecorderLive | ‚úÖ CABLEADO | Pendiente validar backend funciona |

---

## üîç **SISTEMA #1: VOZ EN CHAT**

### **FRONTEND - Implementaci√≥n actual:**

#### **Archivo 1: `src/hooks/useVoiceMode.js`**
```javascript
// Hook principal de voz para chat
export const useVoiceMode = () => {
  const { user } = useAuth();
  const [isVoiceMode, setIsVoiceMode] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  
  // PROBLEMA: No guarda sessionId
  const sendTranscriptToChat = async (text) => {
    const response = await fetch(`${ALE_CORE_URL}/api/ai/chat/v2`, {
      method: 'POST',
      body: JSON.stringify({
        userMessage: text,
        userId: user.id,
        // ‚ùå FALTA: sessionId: currentSessionId
        voiceMode: true
      })
    });
  };
};
```

**üî¥ PROBLEMA IDENTIFICADO #1:**
- Hook NO recibe `sessionId` de la conversaci√≥n actual
- Hook NO pasa `sessionId` al backend
- **Resultado**: Backend crea nueva sesi√≥n ‚Üí pierde contexto

---

#### **Archivo 2: `src/components/VoiceControls.jsx`**
```javascript
// Chips de control de voz (Voz | Micro | Manos Libres)
export default function VoiceControls({ onVoiceModeChange }) {
  const [selectedMode, setSelectedMode] = useState('texto');
  
  const modes = [
    { id: 'voz', label: 'Voz', icon: Volume2 },
    { id: 'micro', label: 'Micro', icon: Mic },
    { id: 'handsfree', label: 'Manos Libres', icon: Radio }
  ];
  
  return (
    <div className="flex gap-2 mb-4">
      {modes.map(mode => (
        <button key={mode.id} onClick={() => handleModeChange(mode.id)}>
          {mode.label}
        </button>
      ))}
    </div>
  );
}
```

**üî¥ PROBLEMA IDENTIFICADO #2:**
- Este componente existe pero **NO SE USA EN NING√öN LADO**
- C√≥digo hu√©rfano, no conectado al chat
- **Resultado**: Los chips de voz no aparecen en la UI

---

#### **Archivo 3: `src/components/Sidebar.jsx`**
```javascript
// Sidebar con bot√≥n de nuevo chat
<button onClick={handleNewConversation}>
  <Plus /> Nuevo Chat
</button>

// ‚ùå NO HAY BOT√ìN DE MICRO EN SIDEBAR
// El usuario reporta: "antes hab√≠a un bot√≥n de micro al lado del bot√≥n azul de nuevo chat"
```

**üî¥ PROBLEMA IDENTIFICADO #3:**
- Bot√≥n de micro en sidebar **NO EXISTE** en c√≥digo actual
- Puede haber sido eliminado en commit anterior
- **Resultado**: Usuario no tiene forma de activar voz desde sidebar

---

### **BACKEND - Implementaci√≥n actual:**

#### **Archivo: `src/api/voice.ts`**
```typescript
// POST /api/voice/stt - Speech-to-Text
router.post('/stt', async (req, res) => {
  const audioBuffer = req.body; // audio blob
  
  // 1. Llamar a Deepgram STT
  const transcript = await deepgramSTT(audioBuffer);
  
  // 2. Retornar texto
  res.json({ text: transcript });
});
```

**‚úÖ BACKEND STT: FUNCIONAL**
- Deepgram convierte audio a texto
- **PERO**: No hay ruta que combine STT + chat en una sola request

---

#### **Archivo: `src/api/chat.ts`**
```typescript
// POST /api/ai/chat/v2 - Chat principal
router.post('/v2', async (req, res) => {
  const { userMessage, userId, sessionId, voiceMode } = req.body;
  
  // ‚ö†Ô∏è PROBLEMA: Si no llega sessionId, crea nueva sesi√≥n
  if (!sessionId) {
    const newSession = await createSession(userId);
    // ‚Üê AQU√ç SE CREA NUEVA SESI√ìN
  }
  
  // ‚úÖ TTS GATE: Solo genera audio si voiceMode=true
  if (voiceMode && response.answer) {
    const audioUrl = await generateTTS(response.answer);
    response.audioUrl = audioUrl;
  }
  
  res.json(response);
});
```

**‚úÖ BACKEND CHAT: TTS GATE IMPLEMENTADO**
- Solo genera audio si `voiceMode: true`
- **PERO**: Frontend no est√° enviando `sessionId`

---

### **FLUJO ACTUAL (ROTO):**

```
Usuario presiona micro
  ‚Üì
useVoiceMode captura audio
  ‚Üì
POST /api/voice/stt ‚Üí transcript
  ‚Üì
Frontend llama POST /api/ai/chat/v2
  ‚Üì
Body: { userMessage, userId, voiceMode: true }
  ‚ùå FALTA: sessionId
  ‚Üì
Backend: if (!sessionId) ‚Üí crea NUEVA sesi√≥n
  ‚Üì
Resultado: PIERDE CONTEXTO ‚ùå
```

---

### **FLUJO CORRECTO (LO QUE DEBE SER):**

```
Usuario presiona micro
  ‚Üì
useVoiceMode captura audio
  ‚Üì
POST /api/voice/stt ‚Üí transcript
  ‚Üì
Frontend llama POST /api/ai/chat/v2
  ‚Üì
Body: { 
  userMessage, 
  userId, 
  sessionId: currentConversationId,  ‚Üê ‚úÖ CR√çTICO
  voiceMode: true 
}
  ‚Üì
Backend: if (sessionId exists) ‚Üí REUSAR sesi√≥n
  ‚Üì
Resultado: MANTIENE CONTEXTO ‚úÖ
```

---

## üîç **SISTEMA #2: VOZ EN REUNIONES**

### **FRONTEND - Implementaci√≥n actual:**

#### **Archivo: `src/features/meetings/components/MeetingsRecorderLive.jsx`**
```javascript
// Grabador de reuniones en vivo (7s chunks)
export default function MeetingsRecorderLive() {
  const [isRecording, setIsRecording] = useState(false);
  const [meetingId, setMeetingId] = useState(null);
  const [liveTranscript, setLiveTranscript] = useState('');
  
  const startRecording = async () => {
    // 1. Iniciar reuni√≥n en backend
    const meeting = await startLiveMeeting(title);
    setMeetingId(meeting.id);
    
    // 2. Pedir permisos de micr√≥fono
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    
    // 3. Capturar chunks de 7s
    const mediaRecorder = new MediaRecorder(stream);
    mediaRecorder.ondataavailable = async (event) => {
      await uploadLiveChunk(meetingId, event.data);
    };
    
    // 4. Polling cada 2s para transcript en vivo
    pollIntervalRef.current = setInterval(async () => {
      const status = await getLiveStatus(meetingId);
      setLiveTranscript(status.transcript);
    }, 2000);
  };
  
  const stopRecording = async () => {
    // 1. Detener grabaci√≥n
    mediaRecorder.stop();
    
    // 2. Finalizar reuni√≥n en backend
    await stopLiveMeeting(meetingId);
    
    // 3. Obtener resultado final
    const result = await getMeetingResult(meetingId);
    setResult(result);
  };
  
  return (
    <div>
      <button onClick={isRecording ? stopRecording : startRecording}>
        {isRecording ? <MicOff /> : <Mic />}
        {isRecording ? 'Detener' : 'Grabar'}
      </button>
      
      {liveTranscript && (
        <div className="transcript">
          {liveTranscript}
        </div>
      )}
      
      {result && (
        <div className="result">
          <h3>Minuta de Reuni√≥n</h3>
          {result.summary}
        </div>
      )}
    </div>
  );
}
```

**‚úÖ FRONTEND REUNIONES: BIEN CABLEADO**
- Captura audio en chunks
- Env√≠a a backend cada 7s
- Hace polling para transcript en vivo
- Muestra resultado final

---

#### **Archivo: `src/services/meetingsService.js`**
```javascript
const BACKEND_URL = import.meta.env.VITE_ALE_CORE_BASE || 
                     import.meta.env.VITE_ALE_CORE_URL || 
                     'https://api.al-eon.com';

// ‚úÖ Iniciar reuni√≥n live
export async function startLiveMeeting(title) {
  const response = await fetch(`${BACKEND_URL}/api/meetings/live/start`, {
    method: 'POST',
    headers: await authHeaders(),
    body: JSON.stringify({
      title,
      mode: 'live',
      auto_send_enabled: false
    })
  });
  return response.json();
}

// ‚úÖ Subir chunk de audio
export async function uploadLiveChunk(meetingId, audioBlob) {
  const formData = new FormData();
  formData.append('audio', audioBlob);
  
  const response = await fetch(`${BACKEND_URL}/api/meetings/live/${meetingId}/chunk`, {
    method: 'POST',
    headers: { 'Authorization': `Bearer ${token}` },
    body: formData
  });
  return response.json();
}

// ‚úÖ Obtener status en vivo
export async function getLiveStatus(meetingId) {
  const response = await fetch(`${BACKEND_URL}/api/meetings/live/${meetingId}/status`, {
    headers: await authHeaders()
  });
  return response.json();
}

// ‚úÖ Detener reuni√≥n
export async function stopLiveMeeting(meetingId) {
  const response = await fetch(`${BACKEND_URL}/api/meetings/live/${meetingId}/stop`, {
    method: 'POST',
    headers: await authHeaders()
  });
  return response.json();
}

// ‚úÖ Obtener resultado final
export async function getMeetingResult(meetingId) {
  const response = await fetch(`${BACKEND_URL}/api/meetings/${meetingId}/result`, {
    headers: await authHeaders()
  });
  return response.json();
}
```

**‚úÖ SERVICIO REUNIONES: BIEN CABLEADO**
- Todas las funciones apuntan a rutas correctas
- URL configurada con fallback a `api.al-eon.com`

---

### **BACKEND - Implementaci√≥n actual:**

#### **Archivo: `src/api/meetings.ts`**
```typescript
/**
 * RUTAS IMPLEMENTADAS:
 * 
 * MODO LIVE (Reuniones presenciales):
 * - POST /api/meetings/live/start       ‚úÖ Iniciar sesi√≥n de grabaci√≥n
 * - POST /api/meetings/live/:id/chunk   ‚úÖ Enviar chunk de audio
 * - GET /api/meetings/live/:id/status   ‚úÖ Status en tiempo real (transcript + notas)
 * - POST /api/meetings/live/:id/stop    ‚úÖ Finalizar grabaci√≥n
 * 
 * MODO UPLOAD (Subir archivo completo):
 * - POST /api/meetings/upload           ‚úÖ Subir mp3/wav/m4a completo
 * - GET /api/meetings/:id/status        ‚úÖ Status del procesamiento
 * - GET /api/meetings/:id/result        ‚úÖ Resultado final
 * - POST /api/meetings/:id/send         ‚úÖ Enviar minuta por email/telegram
 */

// POST /api/meetings/live/start
router.post('/live/start', async (req, res) => {
  const { title, mode, participants } = req.body;
  const userId = req.user.id;
  
  // 1. Crear meeting en DB
  const meeting = await supabase
    .from('meetings')
    .insert({
      owner_user_id: userId,
      title,
      meeting_type: 'live',
      status: 'recording',
      started_at: new Date()
    })
    .select()
    .single();
  
  res.json(meeting.data);
});

// POST /api/meetings/live/:id/chunk
router.post('/live/:id/chunk', async (req, res) => {
  const { id } = req.params;
  const audioBlob = req.body;
  
  // 1. Transcribir chunk con Deepgram
  const transcript = await deepgramSTT(audioBlob, { diarize: true });
  
  // 2. Guardar en DB
  await supabase
    .from('meeting_chunks')
    .insert({
      meeting_id: id,
      transcript_json: transcript,
      chunk_index: chunkIndex++
    });
  
  // 3. Acumular transcript parcial
  liveTranscripts[id] += transcript.text;
  
  res.json({ success: true });
});

// GET /api/meetings/live/:id/status
router.get('/live/:id/status', async (req, res) => {
  const { id } = req.params;
  
  // Retornar transcript acumulado en tiempo real
  res.json({
    meetingId: id,
    status: 'recording',
    transcript: liveTranscripts[id] || '',
    duration: Date.now() - startTimes[id]
  });
});

// POST /api/meetings/live/:id/stop
router.post('/live/:id/stop', async (req, res) => {
  const { id } = req.params;
  
  // 1. Obtener todos los chunks
  const chunks = await supabase
    .from('meeting_chunks')
    .select('*')
    .eq('meeting_id', id)
    .order('chunk_index');
  
  // 2. Generar resumen ejecutivo con Nova Pro
  const summary = await generateMeetingSummary(chunks);
  
  // 3. Actualizar meeting con resultado
  await supabase
    .from('meetings')
    .update({
      status: 'completed',
      transcript_json: chunks,
      summary_json: summary,
      ended_at: new Date()
    })
    .eq('id', id);
  
  res.json({ success: true });
});
```

**‚úÖ BACKEND REUNIONES: IMPLEMENTADO COMPLETO**
- Todas las rutas existen
- Deepgram con diarizaci√≥n configurado
- Transcript en vivo funcional
- Resumen ejecutivo con Nova Pro

---

## üìä **DIAGN√ìSTICO FINAL**

### **SISTEMA #1: VOZ CHAT**

| Componente | Estado | Problema |
|------------|--------|----------|
| **Frontend - useVoiceMode** | üî¥ ROTO | No pasa `sessionId` |
| **Frontend - VoiceControls** | üî¥ HU√âRFANO | Componente no usado |
| **Frontend - Sidebar** | üî¥ FALTANTE | Bot√≥n de micro no existe |
| **Backend - STT** | ‚úÖ FUNCIONA | Deepgram OK |
| **Backend - Chat** | ‚úÖ FUNCIONA | TTS gate implementado |
| **Backend - Session** | ‚ö†Ô∏è PROBLEMA | Crea nueva si no recibe sessionId |

**CAUSA RA√çZ:**
- Frontend NO pasa `sessionId` ‚Üí Backend crea nueva sesi√≥n ‚Üí Pierde contexto

---

### **SISTEMA #2: VOZ REUNIONES**

| Componente | Estado | Problema |
|------------|--------|----------|
| **Frontend - MeetingsRecorderLive** | ‚úÖ CABLEADO | Chunks de 7s + polling |
| **Frontend - meetingsService** | ‚úÖ CABLEADO | Rutas correctas |
| **Backend - /live/start** | ‚úÖ IMPLEMENTADO | Crea meeting |
| **Backend - /live/chunk** | ‚úÖ IMPLEMENTADO | Transcribe con diarizaci√≥n |
| **Backend - /live/status** | ‚úÖ IMPLEMENTADO | Transcript en vivo |
| **Backend - /live/stop** | ‚úÖ IMPLEMENTADO | Genera resumen ejecutivo |

**CAUSA RA√çZ:**
- ‚úÖ TODO BIEN CABLEADO - Solo falta validar que funciona end-to-end

---

## üîß **FIXES REQUERIDOS**

### **FIX #1: VOZ CHAT - PASAR sessionId (P0 CR√çTICO)**

**Archivo a modificar:** `~/Documents/AL-EON/src/hooks/useVoiceMode.js`

**Cambio requerido:**
```javascript
// ANTES (ROTO):
const sendTranscriptToChat = async (text) => {
  const response = await fetch(`${ALE_CORE_URL}/api/ai/chat/v2`, {
    method: 'POST',
    body: JSON.stringify({
      userMessage: text,
      userId: user.id,
      voiceMode: true
    })
  });
};

// DESPU√âS (CORRECTO):
const sendTranscriptToChat = async (text, currentSessionId) => {
  const response = await fetch(`${ALE_CORE_URL}/api/ai/chat/v2`, {
    method: 'POST',
    body: JSON.stringify({
      userMessage: text,
      userId: user.id,
      sessionId: currentSessionId,  // ‚Üê ‚úÖ CR√çTICO
      voiceMode: true
    })
  });
};
```

**C√≥mo obtener `currentSessionId`:**
- El componente de chat debe pasar el `conversationId` actual al hook
- Si no hay conversaci√≥n activa, crear nueva ANTES de enviar transcript

---

### **FIX #2: VOZ CHAT - Switch visible (P0 UX)**

**Archivo a crear:** `~/Documents/AL-EON/src/components/VoiceModeSwitch.jsx`

**Componente nuevo:**
```javascript
export default function VoiceModeSwitch({ isVoiceMode, onToggle }) {
  return (
    <div className="flex items-center gap-2 p-2 bg-white rounded-lg shadow">
      <span className="text-sm text-gray-600">Modo Voz</span>
      <button
        onClick={onToggle}
        className={`relative w-12 h-6 rounded-full transition ${
          isVoiceMode ? 'bg-blue-600' : 'bg-gray-300'
        }`}
      >
        <div className={`absolute top-1 left-1 w-4 h-4 bg-white rounded-full transition ${
          isVoiceMode ? 'translate-x-6' : ''
        }`} />
      </button>
      {isVoiceMode && (
        <span className="text-xs text-blue-600 font-medium">ON</span>
      )}
    </div>
  );
}
```

**D√≥nde agregarlo:**
- En `Sidebar.jsx` al lado del bot√≥n "Nuevo Chat"
- O en la parte superior del chat, siempre visible

---

### **FIX #3: VOZ REUNIONES - Validar end-to-end (P1 VALIDACI√ìN)**

**Prueba requerida:**
1. Abrir `al-eon.com/meetings`
2. Presionar bot√≥n "Grabar Reuni√≥n"
3. Hablar 30 segundos
4. Presionar "Detener"
5. Verificar:
   - ‚úÖ Transcript aparece en vivo
   - ‚úÖ Resumen ejecutivo se genera
   - ‚úÖ Minuta se puede enviar por email

**Logs a verificar (PM2):**
```bash
ssh ubuntu@100.27.201.233 "pm2 logs al-e-core --lines 50 | grep -i meeting"
```

**Logs esperados:**
```
[MEETINGS] POST /api/meetings/live/start - Meeting created: abc123
[MEETINGS] POST /api/meetings/live/abc123/chunk - Chunk #1 transcribed
[MEETINGS] GET /api/meetings/live/abc123/status - Transcript: "Hola esta es..."
[MEETINGS] POST /api/meetings/live/abc123/stop - Generating summary...
[MEETINGS] ‚úÖ Meeting abc123 completed
```

---

## üö® **PRIORIDAD DE FIXES**

| Fix | Sistema | Prioridad | Tiempo | Impacto |
|-----|---------|-----------|--------|---------|
| **#1: Pasar sessionId** | VOZ CHAT | üî¥ P0 | 30 min | CR√çTICO - Sin esto no funciona voz |
| **#2: Switch visible** | VOZ CHAT | üî¥ P0 | 1 hora | CR√çTICO - Usuario no puede activar voz |
| **#3: Validar reuniones** | VOZ REUNIONES | üü° P1 | 15 min | MEDIO - Solo prueba, c√≥digo existe |

---

## üìã **CHECKLIST DE VALIDACI√ìN**

### **VOZ CHAT:**
- [ ] Hook recibe `currentSessionId`
- [ ] Hook pasa `sessionId` al backend
- [ ] Backend reutiliza sesi√≥n existente
- [ ] Switch de voz visible en UI
- [ ] Usuario puede activar/desactivar voz
- [ ] TTS solo se genera si voz est√° ON
- [ ] Contexto se mantiene entre mensajes de voz

### **VOZ REUNIONES:**
- [ ] Bot√≥n "Grabar Reuni√≥n" visible
- [ ] Permisos de micr√≥fono se solicitan
- [ ] Chunks de 7s se env√≠an al backend
- [ ] Transcript aparece en vivo (polling 2s)
- [ ] Bot√≥n "Detener" finaliza grabaci√≥n
- [ ] Resumen ejecutivo se genera
- [ ] Minuta se puede enviar por email

---

## üìû **SIGUIENTE PASO INMEDIATO**

**AHORA (pr√≥ximos 30 minutos):**

1. **Fix VOZ CHAT - sessionId:**
   - Modificar `useVoiceMode.js` para recibir y pasar `sessionId`
   - Commit: "FIX: Pasar sessionId en voz para mantener contexto"
   - Push a GitHub

2. **Fix VOZ CHAT - Switch:**
   - Crear `VoiceModeSwitch.jsx`
   - Agregarlo en `Sidebar.jsx` o header del chat
   - Commit: "FEAT: Switch visible para modo voz"
   - Push a GitHub

3. **Deploy Frontend:**
   - Netlify auto-deploya en 2-3 minutos
   - Validar en `al-eon.com`

4. **Prueba VOZ CHAT:**
   - Activar switch de voz
   - Hablar: "Mi nombre es Patricia"
   - Hablar: "¬øCu√°l es mi nombre?"
   - Verificar: Contexto se mantiene ‚úÖ

5. **Prueba VOZ REUNIONES:**
   - Ir a `/meetings`
   - Grabar 30s
   - Verificar transcript en vivo
   - Verificar resumen ejecutivo

---

**üî¥ NOTA FINAL:** 

El an√°lisis confirma:
- ‚úÖ **VOZ REUNIONES**: Todo bien cableado, solo falta validar
- üî¥ **VOZ CHAT**: Tiene 2 problemas cr√≠ticos (sessionId + switch invisible)

**Prioridad absoluta**: Fix VOZ CHAT primero (30% del producto depende de esto).

---

**Analista**: GitHub Copilot  
**Fecha**: 2026-01-23 17:30 hrs  
**√öltima actualizaci√≥n**: An√°lisis quir√∫rgico completo
