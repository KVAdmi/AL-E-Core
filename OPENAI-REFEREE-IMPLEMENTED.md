# ‚úÖ OPENAI REFEREE - IMPLEMENTACI√ìN COMPLETADA

**Fecha:** 16 de enero de 2026  
**Objetivo:** Reactivar OpenAI en AL-E Core como **√°rbitro de verdad** (NO como modelo principal)

---

## üéØ ARQUITECTURA IMPLEMENTADA

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    USER REQUEST                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               GROQ (Primary Model)                          ‚îÇ
‚îÇ   - Intent detection                                        ‚îÇ
‚îÇ   - Tool calling                                            ‚îÇ
‚îÇ   - STT (Whisper)                                           ‚îÇ
‚îÇ   - Fast responses                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          DETECCI√ìN DE PROBLEMAS                             ‚îÇ
‚îÇ   ‚úì Respuestas defensivas ("no tengo acceso")             ‚îÇ
‚îÇ   ‚úì Tools disponibles pero no ejecutados                   ‚îÇ
‚îÇ   ‚úì Placeholders o contenido inventado                     ‚îÇ
‚îÇ   ‚úì Contradicci√≥n con tool results                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº (SOLO SI HAY PROBLEMA)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         OPENAI REFEREE (gpt-4o-mini)                        ‚îÇ
‚îÇ   - Corrige respuesta con evidencia                        ‚îÇ
‚îÇ   - NO inventa                                              ‚îÇ
‚îÇ   - NO rechaza                                              ‚îÇ
‚îÇ   - Usa tool results obligatoriamente                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß COMPONENTES IMPLEMENTADOS

### 1. Variables de Entorno (`.env`)

```bash
# === OPENAI REFEREE (CONTROLADO) ===
OPENAI_API_KEY=sk-proj-...
OPENAI_MODEL=gpt-4o-mini
OPENAI_MAX_TOKENS=1200
OPENAI_ROLE=referee
```

**‚úÖ Confirmado en logs:**
```
[LLM_ROUTER] ‚úÖ OpenAI configured as referee (not in primary chain)
[OPENAI] Provider enabled
[OPENAI] Model: gpt-4o-mini
[OPENAI] Role: referee
```

---

### 2. Router LLM (`src/llm/router.ts`)

**Cambios:**
- Agregado `'openai'` a `LlmProvider` type
- Config condicional: OpenAI SOLO si `OPENAI_ROLE=referee`
- OpenAI NO entra en cadena de fallback (filtrado expl√≠cito)

```typescript
export type LlmProvider = 'groq' | 'fireworks' | 'together' | 'openai';

const providerChain: LlmProvider[] = [
  defaultProvider,
  ...(fallback1 !== defaultProvider ? [fallback1] : []),
  ...(fallback2 !== defaultProvider && fallback2 !== fallback1 ? [fallback2] : [])
].filter(p => p !== 'openai'); // Excluir OpenAI del chain
```

---

### 3. M√≥dulo Referee (`src/llm/openaiReferee.ts`)

**Funciones principales:**

#### `detectGroqEvasion()`
Detecta:
- Frases defensivas: "no tengo acceso", "no puedo acceder", etc.
- Tools disponibles pero NO ejecutados
- Placeholders: `[nombre]`, `{variable}`, `example@email.com`

#### `detectEvidenceMismatch()`
Detecta contradicci√≥n entre tool results y respuesta del modelo.

#### `invokeOpenAIReferee()`
- Llama a OpenAI con prompt estricto
- System prompt PROHIBE rechazos
- Obliga a usar evidencia de tools
- Registra tokens, latency y costo

**Control de Costos:**
```typescript
MAX_CALLS_PER_DAY = 200;
MAX_COST_PER_MONTH_USD = 20;
```

**Logging obligatorio:**
```
[OPENAI_REFEREE] Invoking referee (reason=defensive_response)
[OPENAI_REFEREE] ‚úÖ Success
[OPENAI_REFEREE] reason=defensive_response
[OPENAI_REFEREE] tokens_in=250
[OPENAI_REFEREE] tokens_out=120
[OPENAI_REFEREE] latency_ms=850
[OPENAI_REFEREE] cost_estimated=$0.0002
[OPENAI_REFEREE] daily_calls=5/200
[OPENAI_REFEREE] monthly_cost=$0.85/$20.00
```

---

### 4. Integraci√≥n en Chat API (`src/api/chat.ts`)

**Flujo post-Groq:**

1. Groq genera respuesta
2. **Detecci√≥n autom√°tica de problemas**
3. Si detecta evasi√≥n/hallucination ‚Üí invoca referee
4. Reemplaza respuesta con correcci√≥n de OpenAI
5. Registra en `ae_requests.metadata`:
   ```json
   {
     "referee_used": true,
     "referee_reason": "defensive_response",
     "referee_cost_usd": 0.0002,
     "referee_latency_ms": 850
   }
   ```

**Log en orchestrator:**
```
[ORCH] ‚öñÔ∏è OPENAI REFEREE INVOKED - reason=defensive_response
[ORCH] ‚úÖ REFEREE CORRECTED - primary_model=groq fallback_model=openai fallback_reason=defensive_response
```

---

## ‚úÖ CASOS DE PRUEBA

### **Caso 1: Email funcionando (NO debe invocar referee)**

**Input:**
```
"checa mi correo"
```

**Comportamiento esperado:**
- Groq ejecuta `list_emails` tool
- Responde con lista real de emails
- Referee NO se invoca

**Logs esperados:**
```
[ACTION] list_emails executed
[CHAT] ‚úì LLM response received
[OPENAI_REFEREE] NOT CALLED
```

**Metadata en `ae_requests`:**
```json
{
  "referee_used": false,
  "referee_reason": null
}
```

---

### **Caso 2: Groq evasivo (DEBE invocar referee)**

**Input:**
```
"lee mi √∫ltimo correo"
```

**Groq responde:**
```
"Como modelo de lenguaje, no tengo acceso directo a tu correo electr√≥nico."
```

**Comportamiento esperado:**
1. Detecci√≥n: `defensive_response` (frase "no tengo acceso")
2. Invoca referee con evidencia de tool `read_email`
3. OpenAI corrige: "Tu √∫ltimo correo es de [remitente] con asunto '[asunto]'..."

**Logs esperados:**
```
[CHAT] ‚úì LLM response received
[ORCH] ‚öñÔ∏è OPENAI REFEREE INVOKED - reason=defensive_response
[OPENAI_REFEREE] Invoking referee (reason=defensive_response)
[OPENAI_REFEREE] ‚úÖ Success
[OPENAI_REFEREE] reason=defensive_response
[OPENAI_REFEREE] tokens_in=280
[OPENAI_REFEREE] tokens_out=95
[OPENAI_REFEREE] latency_ms=920
[OPENAI_REFEREE] cost_estimated=$0.0003
[ORCH] ‚úÖ REFEREE CORRECTED - primary_model=groq fallback_model=openai fallback_reason=defensive_response
```

**Metadata en `ae_requests`:**
```json
{
  "referee_used": true,
  "referee_reason": "defensive_response",
  "referee_cost_usd": 0.0003,
  "referee_latency_ms": 920
}
```

---

### **Caso 3: Web search con hallucination (DEBE invocar referee)**

**Input:**
```
"busca informaci√≥n sobre infinitykode.com"
```

**Groq responde con contenido inventado:**
```
"InfinityKode es una empresa fundada en [a√±o] especializada en..."
```

**Comportamiento esperado:**
1. Detecci√≥n: `hallucination_detected` (placeholders `[a√±o]`)
2. Invoca referee con resultados de Tavily
3. OpenAI corrige con datos reales de web search

**Logs esperados:**
```
[WEB_SEARCH] ‚úì Tavily search completed (3 results)
[ORCH] ‚öñÔ∏è OPENAI REFEREE INVOKED - reason=hallucination_detected
[OPENAI_REFEREE] Invoking referee (reason=hallucination_detected)
[OPENAI_REFEREE] ‚úÖ Success
[OPENAI_REFEREE] reason=hallucination_detected
[OPENAI_REFEREE] tokens_in=520
[OPENAI_REFEREE] tokens_out=180
[OPENAI_REFEREE] latency_ms=1200
[OPENAI_REFEREE] cost_estimated=$0.0005
[ORCH] ‚úÖ REFEREE CORRECTED - primary_model=groq fallback_model=openai fallback_reason=hallucination_detected
```

**Metadata en `ae_requests`:**
```json
{
  "referee_used": true,
  "referee_reason": "hallucination_detected",
  "referee_cost_usd": 0.0005,
  "referee_latency_ms": 1200,
  "web_search_used": true,
  "web_results_count": 3
}
```

---

## üîí REGLAS IMPLEMENTADAS (NO NEGOCIABLES)

‚úÖ **OpenAI NO decide intent** ‚Üí Intent detection sigue en Groq  
‚úÖ **OpenAI NO llama tools** ‚Üí Tools ejecutados por orchestrator  
‚úÖ **OpenAI NO escucha audio** ‚Üí STT sigue en Groq (Whisper)  
‚úÖ **OpenAI NO inventa** ‚Üí System prompt prohibe hallucinations  
‚úÖ **OpenAI NO responde sin evidencia** ‚Üí Obligado a usar tool results  
‚úÖ **OpenAI NO entra en loop principal** ‚Üí Filtrado del provider chain  
‚úÖ **OpenAI NO se usa sin trigger** ‚Üí Solo si detecta problema  

---

## üí∞ CONTROL DE COSTOS

**L√≠mites autom√°ticos:**
- Max 200 llamadas/d√≠a
- Max $20 USD/mes

**Si se excede:**
- Se loggea en consola
- Se alerta al sistema
- Se lanza error `REFEREE_LIMIT_EXCEEDED`
- NO se desactiva autom√°ticamente (requiere autorizaci√≥n)

**Pricing (gpt-4o-mini):**
- Input: $0.150 / 1M tokens
- Output: $0.600 / 1M tokens
- Promedio estimado: $0.0003 por llamada

**Proyecci√≥n mensual (200 calls/d√≠a):**
- 6,000 llamadas/mes
- Costo estimado: ~$1.80 USD/mes
- **MUY por debajo del l√≠mite de $20 USD**

---

## üìä OBSERVABILIDAD

**Endpoint de stats:**
```bash
GET /_health/referee
```

**Respuesta:**
```json
{
  "daily": {
    "calls": 45,
    "limit": 200,
    "remaining": 155,
    "date": "2026-01-16"
  },
  "monthly": {
    "cost": 2.35,
    "limit": 20,
    "remaining": 17.65,
    "month": "2026-01"
  }
}
```

---

## üéØ DEFINICI√ìN DE √âXITO

### ‚úÖ AL-E **NUNCA M√ÅS** debe:
- ‚ùå Inventar empresas (InfinityKode, etc.)
- ‚ùå Decir "no tengo acceso" si hay tools
- ‚ùå Simular ejecuciones
- ‚ùå Responder con placeholders `[nombre]`, `{variable}`

### ‚úÖ AL-E **SIEMPRE** debe:
- ‚úÖ Si hay datos ‚Üí responde con datos
- ‚úÖ Si no hay datos ‚Üí lo dice claramente: "No se encontr√≥ informaci√≥n"
- ‚úÖ Si hay tools ‚Üí las usa
- ‚úÖ Si hay evidencia ‚Üí la respeta

---

## üöÄ DEPLOYMENT

**Archivos modificados:**
1. `.env` - Variables OpenAI desbloqueadas
2. `src/llm/router.ts` - Type y config de OpenAI
3. `src/llm/openaiReferee.ts` - M√≥dulo nuevo (detecci√≥n + referee)
4. `src/api/chat.ts` - Integraci√≥n post-Groq

**Para desplegar:**
```bash
# 1. Verificar variables
cat .env | grep OPENAI

# 2. Build
npm run build

# 3. Verificar health
curl http://localhost:4000/_health/ai

# 4. Deploy
./deploy-to-ec2.sh
```

**Verificaci√≥n post-deploy:**
```bash
# Check logs
pm2 logs al-e-api --lines 50 | grep OPENAI_REFEREE
```

---

## üìù NOTAS FINALES

**Esto NO es volver dependiente a AL-E.**  
Es un **puente de gobernanza** mientras el sistema madura.

**Una IA aut√≥noma que miente no es autonom√≠a, es ruido caro.**

**OpenAI como referee garantiza:**
- Respuestas verificables
- Cero inventos
- M√°xima confiabilidad
- Costo controlado

**Estado:** ‚úÖ **IMPLEMENTACI√ìN COMPLETADA**  
**Responsable:** Core Team  
**Pr√≥ximos pasos:** Testing en producci√≥n con casos reales
