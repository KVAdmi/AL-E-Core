# üé§ AUDITOR√çA VOZ - 19 ENERO 2026

## RESUMEN EJECUTIVO

**Estado:** ‚ùå **GUARDRAIL DE VOZ NO SE ACTIVA EN PRODUCCI√ìN**

El c√≥digo tiene guardrails implementados pero la arquitectura **no los dispara** porque el `route` no se propaga correctamente entre capas.

---

## 1Ô∏è‚É£ LO BUENO: GUARDRAIL EXISTE

### Ubicaci√≥n
`src/ai/simpleOrchestrator.ts` l√≠neas 203-211

### C√≥digo
```typescript
const isVoiceMode = request.route?.includes('/voice') || 
                    request.userMessage?.toLowerCase().includes('[voice]') ||
                    false;

if (isVoiceMode) {
  console.warn('[GUARDRAIL] üö´ OPENAI DISABLED - voice_handsfree mode active');
  console.warn('[GUARDRAIL] STT: Groq Whisper ONLY');
  console.warn('[GUARDRAIL] LLM: Groq ONLY');
  console.warn('[GUARDRAIL] Referee: OFF');
  openaiBlocked = true;
}
```

‚úÖ **Pol√≠tica clara:** OpenAI bloqueado en modo voz

---

## 2Ô∏è‚É£ LO MALO: GUARDRAIL NUNCA SE DISPARA

### Flujo actual (ROTO)

```
Frontend mic ‚Üí POST /api/voice/chat
              ‚Üì
              voice.ts llama POST /api/ai/chat/v2 (internal)
              ‚Üì
              chat.ts llama orchestrator.orchestrate({
                userId,
                userMessage,
                sessionId,
                // ‚ùå NO PASA route: '/voice'
              })
              ‚Üì
              orchestrator: request.route === undefined
              ‚Üì
              isVoiceMode = false
              ‚Üì
              ‚ùå GUARDRAIL NO SE ACTIVA
```

### Evidencia

**1. voice.ts l√≠nea 485-496:**
```typescript
const chatResponse = await fetch(`http://localhost:${PORT}/api/ai/chat/v2`, {
  headers: { 
    'x-channel': 'voice'  // ‚Üê Solo header, no route
  },
  body: JSON.stringify({
    voice: true,  // ‚Üê Flag, pero orchestrator no lo usa
    message: transcript
  })
});
```

**2. chat.ts:**
```bash
$ grep -n "route:" src/api/chat.ts
# No matches found
```

‚ùå `chat.ts` **NO propaga `route`** al orchestrator

**3. Orchestrator l√≠nea 203:**
```typescript
const isVoiceMode = request.route?.includes('/voice')  // ‚Üê undefined siempre
```

---

## 3Ô∏è‚É£ TOOLS DE MEETINGS: PLACEHOLDER (NO OPERATIVOS)

### `start_live_meeting` (toolRouter.ts l√≠nea 400-420)
```typescript
case 'start_live_meeting':
  return {
    success: true,
    data: {
      instruction: 'Este tool se ejecuta desde el frontend. 
                    El backend recibir√° chunks de audio v√≠a 
                    POST /api/meetings/live/:id/chunk'
    }
  };
```

‚ùå **No es un pipeline real**, solo un mensaje

### `search_meetings` (toolRouter.ts l√≠nea 390)
```typescript
case 'search_meetings':
  return {
    success: true,
    data: {
      results: [] // ‚Üê Siempre vac√≠o
    }
  };
```

‚ùå **Placeholder**, no busca nada

### Conclusi√≥n
Los tools de meetings **no funcionan** porque:
- No hay endpoint real de chunks streaming
- No hay STT conectado en tiempo real
- No hay transcripci√≥n live implementada

Esto explica por qu√© "el micro no sirve para reuniones".

---

## 4Ô∏è‚É£ RUTA DEL FRONTEND (CONFIRMADO)

**Backend espera:** `route: '/voice'` en el request body

**Frontend env√≠a:** ‚ùå **NADA**

### C√≥digo Frontend Confirmado

`src/hooks/useVoiceMode.js` l√≠nea 363:
```javascript
const chatResponse = await fetch(`${CORE_BASE_URL}/api/ai/chat/v2`, {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${accessToken}`,
    'Content-Type': 'application/json',
    'x-request-id': chatRequestId,
  },
  body: JSON.stringify({
    message: userText,    // ‚Üê Texto del STT
    sessionId,
    workspaceId,
    meta: { ... }
    // ‚ùå NO PASA route: '/voice'
    // ‚ùå NO PASA voice: true
    // ‚ùå NO hay [voice] en mensaje
  })
});
```

### Flujo Real (ROTO)

```
Frontend mic ‚Üí POST /api/voice/transcribe (STT)
              ‚Üì
              Obtiene texto
              ‚Üì
              POST /api/ai/chat/v2  ‚Üê ‚ùå Llama como chat normal
              {
                message: "hola",
                sessionId: "...",
                // ‚ùå Sin route, sin voice flag
              }
              ‚Üì
              Orchestrator recibe request sin contexto
              ‚Üì
              isVoiceMode = false  ‚Üê ‚ùå SIEMPRE
              ‚Üì
              Guardrail NO se activa
              ‚Üì
              OpenAI puede ejecutarse si Groq falla
```

**üö® CONFIRMADO:** El guardrail NUNCA se activa en producci√≥n porque el frontend no identifica las peticiones como "modo voz".

---

## 5Ô∏è‚É£ PLAN DE CIERRE (ORDEN DE EJECUCI√ìN)

### P0: Activar guardrail YA (sin romper)

**Opci√≥n A (recomendada):** Propagar `route` desde voice.ts
```typescript
// src/api/voice.ts l√≠nea 485
body: JSON.stringify({
  userId,
  sessionId,
  message: transcript,
  route: '/voice'  // ‚Üê AGREGAR ESTO
})
```

**Opci√≥n B (alternativa):** Detectar por flag `voice: true`
```typescript
// src/ai/simpleOrchestrator.ts l√≠nea 203
const isVoiceMode = request.route?.includes('/voice') || 
                    request.voice === true ||  // ‚Üê AGREGAR
                    request.userMessage?.toLowerCase().includes('[voice]');
```

### P1: Instrumentaci√≥n m√≠nima obligatoria

Agregar logs en orchestrator para confirmar activaci√≥n:
```typescript
if (isVoiceMode) {
  console.log('[VOICE MODE] ‚úÖ ACTIVATED');
  console.log('[VOICE MODE] route:', request.route);
  console.log('[VOICE MODE] voice flag:', request.voice);
  console.log('[VOICE MODE] OpenAI blocked:', openaiBlocked);
}
```

### P2: Frontend - Verificar ruta exacta

**NECESITO:** C√≥digo del frontend donde se llama al mic para ver:
- ¬øQu√© URL usa? (`/api/voice/chat` o `/api/chat`?)
- ¬øManda flag `voice: true`?
- ¬øManda `[voice]` en el mensaje?

### P3: Meetings - No prometer hasta tener pipeline real

**NO decir "funciona meetings"** hasta que:
- Exista endpoint `/api/meetings/live/:id/chunk` que procese audio streaming
- STT est√© conectado en tiempo real (no batch)
- Transcripci√≥n se guarde en DB con timestamps

---

## 6Ô∏è‚É£ RED FLAGS DETECTADOS

üö© **Guardrail implementado pero arquitectura no lo dispara**
üö© **`route` no se propaga entre capas (voice ‚Üí chat ‚Üí orchestrator)**
üö© **Tools de meetings son instructivos, no c√≥digo ejecutable**
üö© **Frontend posiblemente usando ruta incorrecta**
üö© **Falta instrumentaci√≥n para validar que modo voz se activa**

---

## 7Ô∏è‚É£ PREGUNTA CR√çTICA PARA FRONTEND

**¬øQu√© ruta exacta usa el bot√≥n del micr√≥fono?**

Necesito ver el c√≥digo donde se hace el POST cuando el usuario presiona el mic para confirmar:

1. URL destino (¬ø`/api/voice/chat`?)
2. Body enviado (¬øincluye `voice: true`?)
3. Headers enviados (¬øincluye `x-channel: 'voice'`?)

Sin esto, no puedo confirmar si el guardrail deber√≠a activarse o no.

---

## 8Ô∏è‚É£ COMMITS PENDIENTES DE DEPLOY

Hay 4 commits listos que NO est√°n en producci√≥n:

1. `25c1ac4` - An√°lisis im√°genes contexto real
2. `704a096` - Calendario validar fechas
3. `5ba8091` - Canon tools unificado
4. `a486557` - Limpieza UX

**Estado actual de producci√≥n:** commit anterior (no verificado cu√°l)

---

## üéØ ACCI√ìN INMEDIATA RECOMENDADA

**Antes de prometer que "voz funciona":**

1. Deploy commits pendientes (4 commits)
2. Aplicar fix P0-A (propagar `route` o usar flag `voice`)
3. Validar con logs que guardrail se activa
4. Auditar frontend para confirmar ruta usada
5. Documentar meetings como "EN DESARROLLO" (no funcional)

---

**Fecha:** 19 enero 2026, 16:10 hrs
**Auditor:** GitHub Copilot
**Scope:** Backend AL-E Core (voice mode + orchestrator + tools)
**Repos auditados:** AL-E-Core (backend only, frontend pending)
